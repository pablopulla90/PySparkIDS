{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################### SPLITTING ORIG #################################\n",
      "Actual time 1572336887.4413905\n",
      "File done\n",
      "It took 3.4997568130493164\n",
      "########################### DONE SPLITTING #################################\n",
      "[][][]\n",
      "0\n",
      "\n",
      "0\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import time, os, random, threading\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#### Last update on April, 4th ########\n",
    "# This script just process the dataset and saves a csv file with the correct format.\n",
    "\n",
    "##TODO: adequate functions to Cloudbook\n",
    "\n",
    "fulldataset = \"./ugredux1g.csv\"\n",
    "#fulldataset = \"C:/Users/albercam/Desktop/july.week5.csv.uniqblacklistremoved\"\n",
    "\n",
    "outpath = \"./output\"\n",
    "#outpath = \"C:/Users/albercam/Desktop/output\"\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "done = []\n",
    "assigned = []\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable. The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = f\"{name}-{tv}\"\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "# DU_0 DOES THIS\n",
    "def split_orig_file():\n",
    "    print(\"########################### SPLITTING ORIG #################################\")\n",
    "    actual = time.time()\n",
    "    print(\"Actual time\", actual)\n",
    "    lines_per_file = 5000000\n",
    "    smallfile = None\n",
    "    with open(fulldataset) as bigfile:\n",
    "        for lineno, line in enumerate(bigfile):\n",
    "            if lineno % lines_per_file == 0:\n",
    "                if smallfile:\n",
    "                    smallfile.close()\n",
    "                    print(\"File done\", lineno)\n",
    "                    done.append('file_{}.csv'.format(lineno))\n",
    "                small_filename = 'file_{}.csv'.format(lineno + lines_per_file)\n",
    "                smallfile = open(outpath+\"/\"+small_filename, \"w\")\n",
    "            smallfile.write(line)\n",
    "        if smallfile:\n",
    "            smallfile.close()\n",
    "            print(\"File done\")\n",
    "\n",
    "    print(\"It took\", time.time()-actual)\n",
    "    print(\"########################### DONE SPLITTING #################################\")\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# HERE WE MUST ASSIGN WHAT DU EXECUTES WHAT FILES             #\n",
    "###############################################################\n",
    "def assign_pieces():\n",
    "    time.sleep(60)\n",
    "    print(done)\n",
    "    print(len(done))\n",
    "    while(len(done)==0):\n",
    "        time.sleep(5)\n",
    "    chosen = random.choice(done)\n",
    "    while(chosen in assigned):\n",
    "        chosen = random.choice(done)\n",
    "    assigned.append(chosen)\n",
    "    print(\"The chosen is\", chosen)\n",
    "    return chosen\n",
    "\n",
    "\n",
    "\n",
    "def process_dataset_file():\n",
    "    #For assigned file execute...\n",
    "    print(\"########################### PROCESSING ASSIGNED PIECES #################################\")\n",
    "    count = 0\n",
    "    for filename in os.listdir(outpath):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            print(\"Processing\", filename)\n",
    "            actual = time.time()\n",
    "            #print(\"Actual time\", actual)\n",
    "            ## Reading the file using chunksize to use less memory. Afterwards it concatenate all the columns into an unique dataframe.\n",
    "            df1 = pd.read_csv(outpath+\"/\"+filename,encoding=ENCODING,low_memory=False,error_bad_lines=False,header=None,chunksize=100000)\n",
    "            df = pd.concat(df1, ignore_index=True)\n",
    "\n",
    "            df.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "            #Set columns name and attach it to the dataframe.\n",
    "            colname = [\"Timestamp\",\"Duration\",\"Src_IP\",\"Dst_IP\",\"Src_Port\",\"Dest_Port\",\"Proto\",\"Flags\",\"Forward_Status\",\"Service_type\",\"Number_of_Packets\",\"Bytes\",\"Result\"]\n",
    "            df.columns=colname\n",
    "\n",
    "            #Lets normalize some of the values of the dataset\n",
    "            encode_numeric_zscore(df, 'Duration')\n",
    "            encode_text_index(df, 'Src_IP')\n",
    "            encode_text_index(df, 'Dst_IP')\n",
    "            encode_text_index(df, 'Src_Port')\n",
    "            encode_text_index(df, 'Dest_Port')\n",
    "            encode_text_dummy(df, 'Proto')\n",
    "            encode_text_dummy(df, 'Flags')\n",
    "            encode_numeric_zscore(df, 'Forward_Status')\n",
    "            encode_numeric_zscore(df, 'Number_of_Packets')\n",
    "            encode_numeric_zscore(df, 'Bytes')\n",
    "\n",
    "            #Drop timestamps -> for now, they are not useful.\n",
    "            df.drop(columns=['Timestamp'],axis=1,inplace=True)\n",
    "\n",
    "            #If background set to 0, if attack set to 1\n",
    "            df.loc[df.Result != 'background', 'Result'] = 1\n",
    "            df.loc[df.Result == 'background', 'Result'] = 0\n",
    "            count+=1\n",
    "            df.to_csv(outpath+'/out'+str(count)+'.csv', header=False, index=False)\n",
    "            print(\"Dataset piece processed in\", time.time()-actual)\n",
    "        \n",
    "        print(\"########################### PIECES PROCESSED #################################\")\n",
    "\n",
    "\n",
    "#DU_0 DOES THIS\n",
    "#Finally everything must be joined:\n",
    "def create_final_dataset():\n",
    "    print(\"########################### PROCESSING FINAL DATASET #################################\")\n",
    "    with open(outpath+\"/DATASET.csv\", 'w') as outfile:\n",
    "        for fname in os.listdir(outpath):\n",
    "            if fname.find(\"out\")!= -1:\n",
    "                print(fname)\n",
    "                with open(outpath+\"/\"+fname) as infile:\n",
    "                    for line in infile:\n",
    "                        outfile.write(line)\n",
    "    print(\"################################## DATASET READY #####################################\")\n",
    "\n",
    "\n",
    "\n",
    "#split_orig_file()\n",
    "#assign_pieces()\n",
    "\n",
    "threading.Thread(target=split_orig_file, args=()).start()\n",
    "\n",
    "worker1 = threading.Thread(target=assign_pieces, args=())\n",
    "worker1.start()\n",
    "worker2 = threading.Thread(target=assign_pieces, args=())\n",
    "worker2.start()\n",
    "worker3 = threading.Thread(target=assign_pieces, args=())\n",
    "worker3.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
