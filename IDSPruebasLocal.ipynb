{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Keras\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from Keras)\n",
      "Collecting numpy>=1.9.1 (from Keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from Keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting h5py (from Keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/12/90/3216b8f6d69905a320352a9ca6802a8e39fdb1cd93133c3d4163db8d5f19/h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting scipy>=0.14 (from Keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/f6/7c16d60aeb3694e5611976cb4f1eaf1c6b7f1e7c55771d691013405a02ea/scipy-1.2.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting pyyaml (from Keras)\n",
      "Collecting six>=1.9.0 (from Keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, six, h5py, keras-applications, keras-preprocessing, scipy, pyyaml, Keras\n",
      "Successfully installed Keras-2.3.1 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 numpy-1.16.5 pyyaml-5.1.2 scipy-1.2.2 six-1.12.0\n",
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/db/83/7d4008ffc2988066ff37f6a0bb6d7b60822367dcb36ba5e39aa7801fda54/pandas-0.24.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.12.0 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2011k (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.5.0 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil>=2.5.0->pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, pytz, six, python-dateutil, pandas\n",
      "Successfully installed numpy-1.16.5 pandas-0.24.2 python-dateutil-2.8.0 pytz-2019.3 six-1.12.0\n",
      "Collecting matplotlib\n",
      "  Using cached https://files.pythonhosted.org/packages/32/6b/0368cfa5e1d1ae169ab7dc78addda3fd5e6262e48d7373a9114bac7caff7/matplotlib-2.2.4-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.7.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting backports.functools-lru-cache (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/03/8e/2424c0e65c4a066e28f539364deee49b6451f8fcd4f718fefa50cc3dcf48/backports.functools_lru_cache-1.5-py2.py3-none-any.whl\n",
      "Collecting subprocess32 (from matplotlib)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/78/cb9248b2289ec31e301137cedbe4ca503a74ca87f88cdbfd2f8be52323bf/kiwisolver-1.1.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting pytz (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Collecting six>=1.10 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/11/fa/0160cd525c62d7abd076a070ff02b2b94de589f1a9789774f17d7c54058e/pyparsing-2.4.2-py2.py3-none-any.whl\n",
      "Collecting setuptools (from kiwisolver>=1.0.1->matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/ea/98/9db5ebb9c33716ab8c45ee355a300facb44575b9b6d68a95fa49e81a2f04/setuptools-41.5.0-py2.py3-none-any.whl\n",
      "Installing collected packages: six, cycler, numpy, backports.functools-lru-cache, subprocess32, setuptools, kiwisolver, pytz, python-dateutil, pyparsing, matplotlib\n",
      "Successfully installed backports.functools-lru-cache-1.5 cycler-0.10.0 kiwisolver-1.1.0 matplotlib-2.2.4 numpy-1.16.5 pyparsing-2.4.2 python-dateutil-2.8.0 pytz-2019.3 setuptools-41.5.0 six-1.12.0 subprocess32-3.5.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade tensorflow\n",
    "!pip install Keras\n",
    "!pip install pandas\n",
    "#!pip install pandas\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCODE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, zero_one_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#{name}-{tv}\n",
    "    \n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = f\"{name}-{tv}\"\n",
    "        df[name2] = l\n",
    "        \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m:>02}:{s:>05.2f}\"\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean())\n",
    "                          >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./julioredux3.csv\n",
      "Read 2493050 rows.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "#ver como llamar con hadoop.\n",
    "try:\n",
    "    path = './julioredux3.csv'\n",
    "    #ugr_file = open(path,'r')\n",
    "    #path = get_file('kddcup.data.gz', origin='http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz')\n",
    "except:\n",
    "    print('Error loading')\n",
    "    raise\n",
    "    \n",
    "print(path) \n",
    "\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "# Download from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "df = pd.read_csv(path, header=None)\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "df.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'te',\n",
    "    'td',\n",
    "    'sa',\n",
    "    'da',\n",
    "    'sp',\n",
    "    'dp',\n",
    "    'pr',\n",
    "    'flg',\n",
    "    'fwd',\n",
    "    'stos',\n",
    "    'pkt',\n",
    "    'byt',\n",
    "    'norm'\n",
    "]\n",
    "\n",
    "# display 5 rows\n",
    "#df[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(df):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(df))\n",
    "    #df = pd.read_csv(path,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "           \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing:                           te       td               sa               da  \\\n",
      "0        2016-07-27 13:43:21   48.380   187.96.221.207     42.219.153.7   \n",
      "1        2016-07-27 13:43:21   48.380     42.219.153.7   187.96.221.207   \n",
      "2        2016-07-27 13:43:25   50.632   42.219.153.191   62.205.150.146   \n",
      "3        2016-07-27 13:43:25   51.052   62.205.150.146   42.219.153.191   \n",
      "4        2016-07-27 13:43:27   46.996    92.225.28.133   42.219.155.111   \n",
      "5        2016-07-27 13:43:27   48.852     143.72.8.137   42.219.154.107   \n",
      "6        2016-07-27 13:43:27   48.852   42.219.154.107     143.72.8.137   \n",
      "7        2016-07-27 13:43:28    0.000     143.72.8.137   42.219.154.121   \n",
      "8        2016-07-27 13:43:28    0.000   42.219.152.249     62.83.121.37   \n",
      "9        2016-07-27 13:43:28    0.000   42.219.154.121     143.72.8.137   \n",
      "10       2016-07-27 13:43:28    0.000   42.219.158.242      57.41.5.186   \n",
      "11       2016-07-27 13:43:28    0.000     62.83.121.37   42.219.152.249   \n",
      "12       2016-07-27 13:43:28   48.528   42.219.154.107     143.72.8.137   \n",
      "13       2016-07-27 13:43:28   48.532     143.72.8.137   42.219.154.107   \n",
      "14       2016-07-27 13:43:28   51.040     143.72.8.137   42.219.154.107   \n",
      "15       2016-07-27 13:43:28   51.040   42.219.154.107     143.72.8.137   \n",
      "16       2016-07-27 13:43:28   55.504   216.53.100.243   42.219.154.186   \n",
      "17       2016-07-27 13:43:28   55.504   42.219.154.186   216.53.100.243   \n",
      "18       2016-07-27 13:43:29    0.000  101.149.196.215    42.219.159.86   \n",
      "19       2016-07-27 13:43:29    0.000   104.101.106.84    42.219.159.82   \n",
      "20       2016-07-27 13:43:29    0.000    104.1.230.190     42.219.153.7   \n",
      "21       2016-07-27 13:43:29    0.000    104.1.230.190     42.219.153.7   \n",
      "22       2016-07-27 13:43:29    0.000    104.1.230.190     42.219.153.7   \n",
      "23       2016-07-27 13:43:29    0.000   106.150.20.105    42.219.155.59   \n",
      "24       2016-07-27 13:43:29    0.000  106.150.248.170    42.219.153.89   \n",
      "25       2016-07-27 13:43:29    0.000  106.152.202.182   42.219.152.249   \n",
      "26       2016-07-27 13:43:29    0.000  113.101.113.103    42.219.159.90   \n",
      "27       2016-07-27 13:43:29    0.000  114.153.155.113   42.219.154.197   \n",
      "28       2016-07-27 13:43:29    0.000  114.153.155.113   42.219.154.197   \n",
      "29       2016-07-27 13:43:29    0.000  114.153.155.113   42.219.154.197   \n",
      "...                      ...      ...              ...              ...   \n",
      "2493020  2016-07-27 14:07:00    3.128    42.219.159.90   67.207.118.174   \n",
      "2493021  2016-07-27 14:07:00    3.136    42.219.159.90    117.45.172.65   \n",
      "2493022  2016-07-27 14:07:00    3.136    42.219.159.90    220.83.26.247   \n",
      "2493023  2016-07-27 14:07:00    3.144    133.54.81.130    42.219.154.97   \n",
      "2493024  2016-07-27 14:07:00    3.144   223.143.202.15     42.219.153.7   \n",
      "2493025  2016-07-27 14:07:00    3.144   42.219.154.154  169.108.204.216   \n",
      "2493026  2016-07-27 14:07:00    3.192  169.108.204.216   42.219.154.154   \n",
      "2493027  2016-07-27 14:07:00    3.204     204.97.92.59   42.219.154.101   \n",
      "2493028  2016-07-27 14:07:00    3.252  223.250.102.186   42.219.158.156   \n",
      "2493029  2016-07-27 14:07:00    3.256     168.38.13.14   42.219.158.156   \n",
      "2493030  2016-07-27 14:07:00    3.256   42.219.158.156     168.38.13.14   \n",
      "2493031  2016-07-27 14:07:00    3.284     204.97.71.84   42.219.156.198   \n",
      "2493032  2016-07-27 14:07:00    3.284   42.219.154.128    49.200.170.17   \n",
      "2493033  2016-07-27 14:07:00    3.344    37.140.226.97   42.219.158.226   \n",
      "2493034  2016-07-27 14:07:00  341.444    69.33.156.137    42.219.153.89   \n",
      "2493035  2016-07-27 14:07:00  341.500    42.219.153.89    69.33.156.137   \n",
      "2493036  2016-07-27 14:07:00  341.508    42.219.153.89    56.201.208.76   \n",
      "2493037  2016-07-27 14:07:00  341.524   223.27.104.151    42.219.153.89   \n",
      "2493038  2016-07-27 14:07:00  341.524    42.219.153.89    78.160.191.60   \n",
      "2493039  2016-07-27 14:07:00  341.600    42.219.153.89   223.27.104.151   \n",
      "2493040  2016-07-27 14:07:00    3.464    42.219.155.28   51.237.230.120   \n",
      "2493041  2016-07-27 14:07:00    3.484    42.219.155.28    51.237.218.27   \n",
      "2493042  2016-07-27 14:07:00    3.492    51.237.218.27    42.219.155.28   \n",
      "2493043  2016-07-27 14:07:00   35.192    60.242.232.73   42.219.153.193   \n",
      "2493044  2016-07-27 14:07:00  353.080    168.40.231.67    42.219.159.89   \n",
      "2493045  2016-07-27 14:07:00    3.536   42.219.154.123     76.163.218.8   \n",
      "2493046  2016-07-27 14:07:00  354.708      209.48.88.5   42.219.159.197   \n",
      "2493047  2016-07-27 14:07:00  355.348    216.51.254.46    42.219.159.82   \n",
      "2493048  2016-07-27 14:07:00  355.800    214.40.71.217   42.219.156.243   \n",
      "2493049  2016-07-27 14:07:00    3.564    49.200.170.17   42.219.154.128   \n",
      "\n",
      "            sp     dp    pr     flg  fwd  stos   pkt      byt        norm  \n",
      "0           53     53   UDP  .A....    0     0     2      209  background  \n",
      "1           53     53   UDP  .A....    0     0     2      167  background  \n",
      "2           80   1838   TCP  .AP...    0     0     9     2082  background  \n",
      "3         1838     80   TCP  .AP...    0     0     9     7118  background  \n",
      "4          443  59867   TCP  .AP...    0     0     4      674  background  \n",
      "5           53  60019   UDP  .A....    0     0     2      188  background  \n",
      "6        60019     53   UDP  .A....    0     0     2      132  background  \n",
      "7           53  40821   UDP  .A....    0     0     1       90  background  \n",
      "8           53  59963   UDP  .A....    0     0     1      159  background  \n",
      "9        45902     53   UDP  .A....    0     0     1       74  background  \n",
      "10       53063    110   TCP  ...R..    0    72     3      120  background  \n",
      "11       59963     53   UDP  .A....    0     0     1       67  background  \n",
      "12       41534     53   UDP  .A....    0     0     2      118  background  \n",
      "13          53  41534   UDP  .A....    0     0     2      422  background  \n",
      "14          53  44571   UDP  .A....    0     0     2      368  background  \n",
      "15       44571     53   UDP  .A....    0     0     2      128  background  \n",
      "16       58144     80   TCP  .A..SF    0     0     5      280  background  \n",
      "17          80  58144   TCP  .A..SF    0     0     4      224  background  \n",
      "18         443  39376   TCP  .A...F    0     0     1       52  background  \n",
      "19       49156   2502   UDP  .A....    0     0     1       70  background  \n",
      "20       31707     53   UDP  .A....    0     0     1       74  background  \n",
      "21       60672     53   UDP  .A....    0     0     1       85  background  \n",
      "22       65508     53   UDP  .A....    0     0     1       77  background  \n",
      "23       40018  41929   UDP  .A....    0     0     1       48  background  \n",
      "24       40022   2063   UDP  .A....    0     0     1      480  background  \n",
      "25       13458     53   UDP  .A....    0     0     1       56  background  \n",
      "26         445  58000   TCP  .A....    0     8     1       40  background  \n",
      "27       33800     80   TCP  ...R..    0    64     1       40  background  \n",
      "28       33801     80   TCP  ...R..    0    64     1       40  background  \n",
      "29       33802     80   TCP  ...R..    0    64     1       40  background  \n",
      "...        ...    ...   ...     ...  ...   ...   ...      ...         ...  \n",
      "2493020  33569    445   TCP  ....S.    0     0     2       96  background  \n",
      "2493021  20330    445   TCP  ....S.    0     0     2       96  background  \n",
      "2493022  14635    445   TCP  ....S.    0     0     2       96  background  \n",
      "2493023  49915     80   TCP  .AP.SF    0    40    21     1340  background  \n",
      "2493024      0   2048  ICMP  .A....    0     0     3      132  background  \n",
      "2493025     80  35358   TCP  .AP.SF    0     0    12    11567  background  \n",
      "2493026  35358     80   TCP  .AP.SF    0     0    16     3734  background  \n",
      "2493027  33679     25   TCP  .APRSF    0     0  1887  2746547  background  \n",
      "2493028  62281    443   TCP  .AP.SF    0    72    19     2326  background  \n",
      "2493029  49718    443   TCP  .AP.SF    0     0    29     5547  background  \n",
      "2493030    443  49718   TCP  .AP.SF    0     0    43    48731  background  \n",
      "2493031     25  41282   TCP  .AP.SF    0     0    16     1858  background  \n",
      "2493032     25  63865   TCP  .AP.S.    0     0     7      619  background  \n",
      "2493033  13839     80   TCP  .A...F    0    72     2      104  background  \n",
      "2493034    443  53790   TCP  .AP.S.    0     0   155    40250  background  \n",
      "2493035  53790    443   TCP  .AP.S.    0     0   117    65076  background  \n",
      "2493036  53788    443   TCP  .AP.S.    0     0    87    27781  background  \n",
      "2493037    443  51460   TCP  .AP...    0     0    80    23082  background  \n",
      "2493038  53783    443   TCP  .AP.S.    0     0   154    25790  background  \n",
      "2493039  51460    443   TCP  .AP...    0     0    80    32313  background  \n",
      "2493040    443   3095   TCP  .APRSF    0     0    10     3344  background  \n",
      "2493041    443  14490   TCP  .APRSF    0     0    10     3344  background  \n",
      "2493042  14490    443   TCP  .APRSF    0     0    13     2913  background  \n",
      "2493043  55864     80   TCP  .AP.SF    0    40    12      869  background  \n",
      "2493044    161  54123   UDP  .A....    0     0   429    49591  background  \n",
      "2493045     80  43160   TCP  .A...F    0     0     5      260  background  \n",
      "2493046    161  55005   UDP  .A....    0     0   420    61727  background  \n",
      "2493047  44719   8000   TCP  .AP...    0     0    72     3936  background  \n",
      "2493048   2200  41001   TCP  .AP...    0     0   339    14238  background  \n",
      "2493049  63865     25   TCP  .APRS.    0    72    11      504  background  \n",
      "\n",
      "[2493050 rows x 13 columns]\n",
      "2493050 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** te:1416 (0%)\n",
      "** td:30875 (1%)\n",
      "** sa:80466 (3%)\n",
      "** da:220607 (8%)\n",
      "** sp:64718 (2%)\n",
      "** dp:64286 (2%)\n",
      "** pr:[TCP:65.4%,UDP:33.74%,ICMP:0.79%,GRE:0.05%,ESP:0.02%,IPIP:0.0%,IPv6:0.0%]\n",
      "** flg:[.A....:38.07%,.AP.SF:29.14%,....S.:9.0%,.AP.S.:4.68%,.AP...:4.23%,.APRSF:4.17%,.A...F:2.63%,.A..SF:2.18%,.APRS.:1.57%,.AP..F:1.19%,...R..:1.1%,.A..S.:0.76%,.A.R..:0.68%,.APR..:0.15%,.A.R.F:0.15%,.A.RS.:0.12%,.APR.F:0.12%,.A.RSF:0.03%,...RS.:0.02%,......:0.0%,..P.S.:0.0%,UA...F:0.0%]\n",
      "** fwd:[0:100.0%]\n",
      "** stos:[0:83.34%,40:6.57%,72:6.46%,2:1.2%,8:0.76%,64:0.52%,4:0.29%,24:0.23%,26:0.18%,192:0.16%,16:0.05%,200:0.05%,104:0.04%,75:0.03%,74:0.02%,42:0.01%,184:0.01%,80:0.01%,20:0.01%,56:0.01%,10:0.01%,28:0.0%,96:0.0%,196:0.0%,43:0.0%,6:0.0%,12:0.0%,32:0.0%,48:0.0%,66:0.0%,44:0.0%,208:0.0%,73:0.0%,76:0.0%,3:0.0%,23:0.0%,202:0.0%,224:0.0%,216:0.0%,9:0.0%,88:0.0%,194:0.0%,1:0.0%]\n",
      "** pkt:3865 (0%)\n",
      "** byt:86592 (3%)\n",
      "** norm:[background:99.73%,blacklist:0.27%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "analyze(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14964378 entries, 0 to 14964377\n",
      "Data columns (total 13 columns):\n",
      "te      object\n",
      "td      float64\n",
      "sa      object\n",
      "da      object\n",
      "sp      int64\n",
      "dp      int64\n",
      "pr      object\n",
      "flg     object\n",
      "fwd     int64\n",
      "stos    int64\n",
      "pkt     int64\n",
      "byt     int64\n",
      "norm    object\n",
      "dtypes: float64(1), int64(6), object(6)\n",
      "memory usage: 1.4+ GB\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>td</th>\n",
       "      <th>sa</th>\n",
       "      <th>da</th>\n",
       "      <th>sp</th>\n",
       "      <th>dp</th>\n",
       "      <th>pr</th>\n",
       "      <th>flg</th>\n",
       "      <th>fwd</th>\n",
       "      <th>stos</th>\n",
       "      <th>pkt</th>\n",
       "      <th>byt</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21524</td>\n",
       "      <td>2550</td>\n",
       "      <td>-1.161711</td>\n",
       "      <td>-0.677528</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.656043</td>\n",
       "      <td>-0.01964</td>\n",
       "      <td>-0.010090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>138534</td>\n",
       "      <td>2573</td>\n",
       "      <td>-1.164591</td>\n",
       "      <td>1.089758</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.656043</td>\n",
       "      <td>-0.01964</td>\n",
       "      <td>-0.010038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>138534</td>\n",
       "      <td>2573</td>\n",
       "      <td>-1.164591</td>\n",
       "      <td>1.327161</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.656043</td>\n",
       "      <td>-0.01964</td>\n",
       "      <td>-0.010037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>138534</td>\n",
       "      <td>3656</td>\n",
       "      <td>-1.164591</td>\n",
       "      <td>0.859621</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.656043</td>\n",
       "      <td>-0.01964</td>\n",
       "      <td>-0.010060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>138534</td>\n",
       "      <td>3659</td>\n",
       "      <td>-1.164591</td>\n",
       "      <td>1.113931</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.656043</td>\n",
       "      <td>-0.01964</td>\n",
       "      <td>-0.010068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   td      sa    da        sp        dp  pr  flg  fwd      stos      pkt  \\\n",
       "0   0   21524  2550 -1.161711 -0.677528   6    5    0 -0.656043 -0.01964   \n",
       "1   0  138534  2573 -1.164591  1.089758   6    5    0 -0.656043 -0.01964   \n",
       "2   0  138534  2573 -1.164591  1.327161   6    5    0 -0.656043 -0.01964   \n",
       "3   0  138534  3656 -1.164591  0.859621   6    5    0 -0.656043 -0.01964   \n",
       "4   0  138534  3659 -1.164591  1.113931   6    5    0 -0.656043 -0.01964   \n",
       "\n",
       "        byt  norm  \n",
       "0 -0.010090     1  \n",
       "1 -0.010038     1  \n",
       "2 -0.010037     1  \n",
       "3 -0.010060     1  \n",
       "4 -0.010068     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "df.drop(['te'], axis=1, inplace=True)\n",
    "\n",
    "#encode_text_index(df, 'te')\n",
    "#print (\"1\")\n",
    "encode_text_index(df, 'td')\n",
    "print (\"2\")\n",
    "encode_text_index(df, 'sa')\n",
    "print (\"3\")\n",
    "encode_text_index(df, 'da')\n",
    "print (\"4\")\n",
    "encode_numeric_zscore(df, 'sp')\n",
    "print (\"5\")\n",
    "encode_numeric_zscore(df, 'dp')\n",
    "print (\"6\")\n",
    "encode_text_index(df, 'pr')\n",
    "print (\"7\")\n",
    "encode_text_index(df, 'flg')\n",
    "print (\"8\")\n",
    "encode_text_index(df, 'fwd')\n",
    "print (\"9\")\n",
    "encode_numeric_zscore(df, 'stos')\n",
    "print (\"10\")\n",
    "encode_numeric_zscore(df, 'pkt')\n",
    "print (\"11\")\n",
    "encode_numeric_zscore(df, 'byt')\n",
    "print (\"12\")\n",
    "#encode_text_dummy(df, 'norm')\n",
    "outcomes = encode_text_index(df, 'norm')\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "#df.dropna(inplace=True,axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PabloPM\\.conda\\envs\\idsEnvir\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\PabloPM\\.conda\\envs\\idsEnvir\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11223283 samples, validate on 3741095 samples\n",
      "Epoch 1/1000\n",
      " - 562s - loss: 0.0522 - val_loss: 0.0527\n",
      "Epoch 2/1000\n",
      " - 592s - loss: 0.0520 - val_loss: 0.0527\n",
      "Epoch 3/1000\n",
      " - 569s - loss: 0.0520 - val_loss: 0.0527\n",
      "Epoch 4/1000\n",
      " - 648s - loss: 0.0520 - val_loss: 0.0527\n",
      "Epoch 5/1000\n",
      " - 670s - loss: 0.0520 - val_loss: 0.0527\n",
      "Epoch 6/1000\n",
      " - 786s - loss: 0.0520 - val_loss: 0.0527\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e243918dd8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "# Break into X (predictors) & y (prediction)\n",
    "x, y = to_xy(df,'norm')\n",
    "\n",
    "# Create a test/train split.  25% test\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='random_normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "#Cambia 1 por 2\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "tensorboard = TensorBoard(log_dir=\"tb/{}\", histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor, tensorboard],verbose=2,epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.9967290325426111\n"
     ]
    }
   ],
   "source": [
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
